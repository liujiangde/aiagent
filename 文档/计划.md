## 目标

* 搭建从零到生产的系统化学习与实作路径（8–10周可完成）

* 掌握 Agent 核心能力：工具调用、检索增强（RAG）、记忆与上下文管理、规划与执行、多智能体协作、评估与安全

* 产出三类可运行作品：命令行助手、检索问答助理、具工具与工作流的生产级服务

## 整体路线（阶段式）

### 阶段 0：基础打底（1 周）

* 了解 LLM 基础：Token/上下文窗口、温度、提示工程（角色/指令/少样本/输出格式）

### LLM 基础速查（快速入门资料）

- Token
  - 文本被拆分为最小单元（token），长度与费用都按 token 计。
  - 英文大约 4 字符/词一个 token，中文常以字或词片段计；不同模型分词略有差异。
  - 上下文窗口限制的是“输入+输出”的总 token 数；超限需压缩或分批。

- 上下文窗口（Context Window）
  - 影响能放入多少历史与知识，窗口越大延迟与成本越高。
  - 策略：摘要历史（对话压缩）、只保留关键字段、启用检索（RAG）而非长提示。
  - 任务型对话优先“结构化状态”而非盲目拼接历史。

- 采样与温度/Top-p
  - 温度（`temperature`）：控制随机性；0 更确定，0.7 较有创造力，>1 容易跑题。
  - Top-p（核采样）：限制概率质量的采样范围；与温度二选一调参即可。
  - 建议：结构化任务 `temperature=0`；创意任务 `0.7±`；避免同时大幅提高温度与 top-p。

- 频率/存在惩罚
  - 频率惩罚减少重复词句，存在惩罚鼓励引入新词；一般默认不改，遇到复读再调整。

- 提示工程（Prompt Engineering）
  - 角色（System）：限定身份与风格，如“你是严格的结构化信息抽取器”。
  - 指令（User）：任务目标与约束，避免歧义，给出输入输出合同。
  - 少样本（Examples）：2–3 个高质量示例，覆盖常见/边界情况。
  - 输出格式：明确 JSON/Markdown，并给出 schema 或样例；必要时要求“只输出 JSON”。

- JSON 输出示例（结构化合同）

```json
{
  "company": "示例科技有限公司",
  "founded_year": 2018,
  "domains": ["ai", "cloud"],
  "hq_city": "上海",
  "is_public": false
}
```

- 提示模板示例（信息抽取）

```
System: 你是严格的结构化抽取器，只输出合法 JSON，禁止多余文本。
User: 从下述文本中抽取公司名、成立年份、领域、总部城市、是否上市。
Input: ……（原始文本）
Output JSON Schema（示例值见上）：
{
  "company": string,
  "founded_year": number,
  "domains": string[],
  "hq_city": string,
  "is_public": boolean
}
```

- 常见坑与规避
  - 输出漂移：开启严格 JSON 模式或在失败时重试并校验解析。
  - 指令歧义：列出“必须/禁止/边界”清单；为无法确定的字段设默认或 "unknown"。
  - 过长历史：使用对话摘要与关键状态表；检索而非整段拼接。

- 快速练习（30–60 分钟）
  - 写 3 个不同任务的提示（摘要、分类、抽取），分别在 `temperature=0/0.7` 比较输出差异。
  - 设计一个 JSON 结构合同，对 5 条输入跑批量，统计“可解析率”和“字段完整率”。
  - 将同一任务加入 2 个少样本示例，观察性能变化并记录结论。

- 推荐资料
  - OpenAI API 与结构化输出指南（JSON/函数调用） 
  https://cloud.tencent.com/developer/article/2454543
  - Anthropic Prompting 指南（角色/约束/少样本）
  - LangChain 提示模板与 RAG 基础文档（Python/TS）



* 学习 Agent 概念：ReAct（推理+行动）、函数调用（Tool Use）、Planner-Executor 架构

* 环境准备：Python 或 TypeScript 二选一，API Key 管理（dotenv）、包管理、虚拟环境


### 阶段 1：最小可用 Agent（1 周）

* 目标：一个可交互的命令行助手（CLI）

* 内容：调用主流模型（OpenAI/Anthropic 或本地 Ollama），完成简单问答与结构化输出

* 要点：稳定输出（JSON Schema/函数调用）、基础日志与错误处理

### 阶段 2：工具调用能力（1–2 周）

* 目标：让 Agent 能“做事”而不仅是“说话”

* 内容：设计工具接口（读写文件、调用 HTTP API、日期/搜索）、安全沙箱（限制文件路径/速率）

* 要点：工具签名与校验、幂等与错误重试、最小权限原则

### 阶段 3：知识检索与记忆（1–2 周）

* 目标：实现 RAG 与短/长时记忆

* 内容：文档嵌入与向量库、检索重排序、片段压缩、对话记忆（会话摘要/知识库）

* 要点：检索评估（Recall/Precision）、提示结构化（检索→推理→回答）

### 阶段 4：规划与多智能体（1–2 周）

* 目标：复杂任务分解与协作

* 内容：任务规划器（高层 Plan）、执行器（工具选择与控制循环）、多 Agent 角色分工（研究员/执行员/审阅员）

* 要点：循环退出条件、任务状态机、避免工具调用死循环

### 阶段 5：评估、监控与安全（1 周）

* 目标：可度量、可回溯、可控制

* 内容：日志/追踪（请求/响应/成本）、离线评估集（用例与断言）、在线反馈收集

* 要点：输出校验、PII/敏感信息防护、越权行为检测、速率与成本治理

### 阶段 6：产品化与部署（1 周）

* 目标：将 Agent 以 API/服务或 GUI 发布

* 内容：HTTP 服务（FastAPI/Express）、前端简界面（Next.js/Vite）、容器化与云部署（Docker + 平台）

* 要点：并发与队列、会话持久化、配置与密钥管理、降级与兜底

## 技术选型建议

* 语言：

  * Python（生态成熟、数据/检索工具丰富、快速原型）

  * TypeScript（前后端统一、Web 友好、强类型）

* 模型：

  * 云端：OpenAI（函数调用/工具用法好）、Anthropic、Google

  * 本地：Ollama（拉取 Llama/Mistral/Qwen 等）、llama.cpp（离线）

* 框架（任选其一或组合）：

  * LangChain（链式与 RAG生态完整，Python/TS 均可）

  * AutoGen/CrewAI（多智能体协作与角色分工）

  * OpenAI Assistants/Function Calling（原生函数调用与检索）

* 向量库：FAISS（本地）、Chroma（易用）、Milvus/Weaviate（服务化）

* 日志评估：LangSmith、OpenTelemetry、自建数据库（Postgres/SQLite）

## 学习与实作里程碑

* 里程碑 A（第 2 周）：命令行助手完成，支持结构化输出与基本工具（时间/文件读）

* 里程碑 B（第 4 周）：RAG 检索问答上线，支持 PDF/网页分块与检索重排序

* 里程碑 C（第 6 周）：Planner-Executor 工作流完成，能分解并执行多步任务

* 里程碑 D（第 8–10 周）：部署生产级服务，带日志、监控、权限与成本治理

## 项目练习（循序渐进）

* 练习 1：CLI 问答助理（带 JSON 输出与错误重试）

* 练习 2：文件管家 Agent（列目录、读写/总结文档，限制到工作区）

* 练习 3：RAG 助理（导入你自己的知识库，支持检索→重排序→回答）

* 练习 4：网页数据采集 Agent（集成 HTTP/爬取工具，生成结构化表）

* 练习 5：邮件/工单分拣 Agent（分类、生成回复草稿，人工确认后发送）

* 练习 6：多智能体工作流（研究员/执行员/审阅员协作完成复杂任务）

## 架构与目录（参考）

* `app/`：服务入口（API/CLI）

* `agents/`：角色与策略（提示、工具清单、停止条件）

* `tools/`：工具适配层（签名、校验、幂等）

* `memory/`：会话与长期记忆（摘要、向量库）

* `retrieval/`：索引与检索（分块、嵌入、重排）

* `workflows/`：Planner-Executor 与状态机

* `eval/`：用例、断言与回归测试

* `infra/`：配置、密钥、部署脚本

## 关键能力要点

* 提示工程：指令清晰、输出模式固定（JSON/Markdown）、少样本示例

* 工具调用：函数签名与模式匹配、输入校验、失败重试与超时

* 记忆：短期（对话摘要/拼接）、长期（向量库 + 压缩）

* 检索：合理分块、嵌入质量、重排序与引用证据

* 规划：任务分解、动态工具选择、循环退出/兜底策略

* 安全：最小权限、越权检测、敏感信息屏蔽、速率与成本限流

* 评估：离线数据集 + 在线反馈闭环，回归测试

## 部署与运维

* 服务形态：REST API + 前端薄层，或仅 CLI

* 并发与稳定：请求队列、任务超时、断点续做（持久化状态）

* 监控：请求耗时/成本、失败率、工具使用分布、检索命中率

* 成本治理：模型选择（大小/上下文）、压缩与裁剪、缓存（提示/嵌入/检索）

## 推荐资源

* 课程与文档：OpenAI/Anthropic/Google 官方指南、LangChain/AutoGen/CrewAI 文档

* 检索：RAG 教程与示例（LangChain、Haystack）、向量库文档（FAISS/Chroma/Milvus）

* 安全与评估：模型输出安全指南、评估框架与最佳实践

## 下一步（执行准备）

* 确认你选用的语言栈（Python 或 TypeScript）与目标模型（云端或本地）

* 我将据此生成最小可用项目骨架与第一版 CLI 助手，并逐周推进各里程碑

